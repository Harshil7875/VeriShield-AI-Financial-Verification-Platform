# **Notebook: 01-GNN-DataPrep-3.ipynb**

This notebook **prepares** VeriShield synthetic data (including **users**, **businesses**, and **IP** nodes) for **GNN usage** in PyTorch Geometric or another graph library. It reads **real** IP fraud labels generated by **`data-gen-v1.py`**, applies basic feature engineering, and saves the final arrays for **multi-node-type** GNN experiments.

## **1. Purpose**

- **Load** the synergy-based CSV outputs (`synthetic_users.csv`, `synthetic_businesses.csv`, `ip_nodes.csv`) created by **`data-gen-v1.py`**.  
- **Validate & clean** the relationship CSVs (e.g., `user_user_relationships.csv`, `user_business_relationships.csv`, `user_ip_relationships.csv`) so there are no invalid IDs.  
- **Feature Engineering**:  
  - Map user segments, phone/email suspiciousness, ring leader flags, etc.  
  - Map business watchlist flags, suspicious names, and log-transformed business age.  
  - (Optionally) create IP features—currently left empty or minimal.  
- **Assign Node IDs** for users, businesses, and IPs (0-based indices).  
- **Build** edge lists for user→user, user→business, and user→IP links.  
- **Create** `.npy` **feature** arrays and **label** arrays for each node type (user, business, IP).  
- **Generate** train/val/test **masks** for all node types (users, businesses, IPs) if desired.  
- **Save** everything to a `processed_gnn` folder for later GNN training.

## **2. Key Steps & Cells**

1. **Cell 2: Configuration**  
   - Set `SCENARIO = "high_fraud"` (or another scenario).  
   - Point `DATA_BASE_PATH` to where `data-gen-v1.py` saved CSVs (e.g., `data-v1/high_fraud/`).  
   - Choose `SINGLE_TASK_USER_ONLY = False` if you want multi-task classification (including businesses), and `DO_SPLIT=True` to create train/val/test masks.

2. **Cell 3: Load CSVs**  
   - Reads `synthetic_users.csv`, `synthetic_businesses.csv`, `ip_nodes.csv`.  
   - Reads `user_ip_relationships.csv`, `user_business_relationships.csv`, `user_user_relationships.csv`.  
   - Prints shapes for a quick sanity check.

3. **Cell 4: Basic Validation**  
   - Checks that `user_id` and `business_id` in relationship files are in valid ranges.  
   - Drops out-of-range edges (if any).

4. **Cell 5: Feature Engineering**  
   - Encodes user segments (`money_mule`, `casual`), ring leader flags, phone/email suspiciousness, etc.  
   - Adds business features for watchlist countries, suspicious names, log-scale business age.

5. **Cell 6: Node ID Assignment & Edge Building**  
   - Assigns 0-based `node_id` to users/businesses/IPs.  
   - Builds **edges** for user→user (undirected, duplicates each edge), user→business, user→IP.

6. **Cell 7: Creating Feature Arrays & Labels**  
   - **Users**: collects the columns `[segment_code, is_ring_leader, ip_count_log, phone_susp, email_susp, country_watch, burst_signup]` as features, `fraud_label` as user_labels.  
   - **Businesses**: `[watchlist_regctry, susp_name_flag, biz_age_log]` as features, `fraud_label` as biz_labels.  
   - **IPs**: no default columns, but does load `ip_nodes['fraud_label']` for IP classification.  
   - Creates minimal Nx0 feature matrix if no explicit IP features exist.

7. **Cell 8: Train/Val/Test Splits**  
   - Splits each node type into train/val/test sets (by default 70/15/15).  
   - Saves boolean masks like `train_mask_users.npy`.

8. **Cell 9: Saving Processed Data**  
   - Saves `.npy` arrays for **features**, **labels**, **edges**, and **masks** in `processed_gnn/`.  
   - Writes a `metadata.json` capturing scenario info, feature columns, and edge counts.

## **3. Outputs**

After running this notebook, you’ll find a new folder:

```
data-v1/<SCENARIO>/processed_gnn/
├── user_features.npy
├── user_labels.npy
├── biz_features.npy
├── biz_labels.npy
├── ip_features.npy
├── ip_labels.npy
├── edge_user_user.npy
├── edge_user_biz.npy
├── edge_user_ip.npy
├── train_mask_users.npy / val_mask_users.npy / test_mask_users.npy
├── train_mask_biz.npy   / val_mask_biz.npy   / test_mask_biz.npy
├── train_mask_ip.npy    / val_mask_ip.npy    / test_mask_ip.npy
└── metadata.json
```

**`metadata.json`** describes scenario = “high_fraud” (or whichever was chosen), node counts, feature columns, etc.

## **4. Usage**

1. **Update** `SCENARIO` and `DATA_BASE_PATH` in **Cell 2** if you’ve generated a different scenario or have a unique folder structure.  
2. **Run** the cells in order.  
3. **Check** the final print statements for confirmation that `.npy` files were saved to `processed_gnn/`.  
4. **Proceed** to a GNN training notebook (like **`02-Model-Training-GNN-PyTorch-4.ipynb`**) to train a **multi-edge** GNN on these arrays.

## **5. Notes**

- **IP Node Labels**: This notebook reads real `fraud_label` from `ip_nodes.csv`, enabling IP classification in multi-task GNN scenarios.  
- **Empty IP Features**: By default, IP nodes have zero features. You can add columns (e.g. `ip_country`, `ip_suspicious_flag`) in **`data-gen-v1.py`** if you’d like to expand IP inputs.  
- **Edge Duplicates**: For `user->user` edges, each edge is stored twice (undirected). If you want a directed approach, remove the second line in the building loop.

---

**In summary**, **`01-GNN-DataPrep-3.ipynb`** converts synergy-based CSV data (users, businesses, IPs) into GNN-ready `.npy` arrays, preserving real IP labels for multi-task classification. After completion, you can feed these `.npy` files into a **PyTorch Geometric** pipeline to train a **heterogeneous** GNN that detects fraud across multiple node types.