# **Notebook: `01-GNN-DataPrep.ipynb`**

## **Overview**

This notebook transforms **VeriShield synthetic data** (users, businesses, and their relationships) into **graph-ready** arrays for **Graph Neural Network (GNN)** experiments. By extracting numeric features, assigning node indices, and building edge lists, it sets the foundation for **ring-based fraud detection** or **multi-owner analysis** using libraries like PyTorch Geometric or DGL.

### Key Objectives

1. **Load Scenario Data**: Reads user, business, and relationship CSVs generated by `refined_data_generator.py`.  
2. **Feature Engineering**: Converts categorical fields (e.g., user segments, suspicious signals) into numeric tensors, handling missing values.  
3. **Node & Edge Mapping**:  
   - Assigns **0-based IDs** to users and businesses.  
   - Builds **user–user** edges (for ring leaders) and **user–business** edges (for ownership).  
4. **Train/Val/Test Splits** (Optional): Splits user nodes into **70/15/15** sets (default) if you want to train and evaluate a classification model.  
5. **Save Artifacts**: Exports `.npy` arrays (features, labels, edge lists, masks) under a `processed_gnn/` subfolder for direct usage in GNN libraries.

---

## **Usage & Configuration**

1. **Set the `SCENARIO`**  
   - For example: `SCENARIO = "high_fraud"` if you have data in `data_generators/data/high_fraud/`.  
   - Adjust `DATA_BASE_PATH` if your folder structure differs from the default.

2. **Run the Notebook**  
   - Launch `01-GNN-DataPrep.ipynb` from `notebooks/Model_Training/`.  
   - Confirm the CSV files (`synthetic_users.csv`, etc.) exist in your scenario path.  
   - Execute the cells in order to generate GNN-compatible files.

3. **Optional Settings**  
   - **`SINGLE_TASK_USER_ONLY`**: If `True`, you focus on classifying user fraud. You can still store business features and labels for multi-task approaches later.  
   - **Splits**: Toggle `DO_SPLIT` to generate train/val/test masks for user nodes. Adjust `TRAIN_RATIO`, `VAL_RATIO`, `TEST_RATIO` as needed.

---

## **Notebook Structure**

1. **Cell 1: Imports & Global Settings**  
   - Loads core libraries (`pandas`, `numpy`) plus optional PyTorch. Sets up display configs.

2. **Cell 2: Configuration**  
   - Defines scenario paths, output subfolder, and splitting parameters.  
   - Creates a `processed_gnn/` directory if it doesn’t exist.

3. **Cell 3: Load CSVs**  
   - Reads `synthetic_users.csv`, `synthetic_businesses.csv`, `user_business_relationships.csv`, and `user_user_relationships.csv`.  
   - Prints shapes to confirm data integrity.

4. **Cell 4: Basic Validation & Checks**  
   - Ensures no out-of-range user/business IDs in the relationship tables.  
   - Drops any invalid edges.

5. **Cell 5: Feature Engineering**  
   - Encodes user segments (`segment_code`), ring-leader flags, phone/email suspiciousness, etc.  
   - Marks watchlist countries or suspicious business names.  
   - Log-transforms certain numeric fields (e.g., `ip_count_log` for users, `biz_age_log` for businesses).

6. **Cell 6: Node ID Assignment & Edge Building**  
   - Converts `user_id` and `business_id` to **0-based** indices (`node_id`).  
   - Builds **user–user** edge pairs (optionally duplicating for undirected edges).  
   - Builds **user–business** edge pairs.

7. **Cell 7: Creating Feature Arrays & Labels**  
   - Selects a list of columns for user node features (e.g., `segment_code`, `ip_count_log`).  
   - Selects a list of columns for business node features (e.g., `watchlist_regctry`, `susp_name_flag`).  
   - Extracts **fraud_label** vectors for users and businesses.

8. **Cell 8: Train/Val/Test Splits**  
   - If `DO_SPLIT = True`, randomly splits user node indices into train/val/test sets, creating boolean masks.  
   - This is essential if you want to do node classification in a GNN pipeline.

9. **Cell 9: Saving Processed Data**  
   - Saves numpy arrays (`user_features.npy`, `biz_features.npy`, `user_labels.npy`, `biz_labels.npy`, and edges).  
   - Saves optional user masks (`train_mask_users.npy`, etc.) for splits.  
   - Writes a `metadata.json` capturing scenario details, edge counts, and feature columns.

---

## **Output Files**

All outputs go to:  
```
/path/to/data_generators/data/<SCENARIO>/processed_gnn/
```
Typical files include:

- **`user_features.npy`**: shape `[num_users, user_feature_dim]`  
- **`user_labels.npy`**: integer array `[num_users]` with 0/1 fraud labels  
- **`biz_features.npy`**: shape `[num_businesses, biz_feature_dim]`  
- **`biz_labels.npy`**: integer array `[num_businesses]` with 0/1 fraud labels  
- **`edge_user_user.npy`**: shape `[2, E_uu]`, storing from→to user IDs (possibly doubled for undirected)  
- **`edge_user_biz.npy`**: shape `[2, E_ub]`, storing user→business IDs  
- **Masks** (if `DO_SPLIT=True`): `train_mask_users.npy`, `val_mask_users.npy`, `test_mask_users.npy`  
- **`metadata.json`**: scenario, feature column lists, ratio splits, etc.

---

## **Use in GNN Libraries**

1. **PyTorch Geometric**  
   - Load arrays using `np.load`.  
   - Construct a **HeteroData** object:
     ```python
     from torch_geometric.data import HeteroData
     data = HeteroData()
     data['user'].x = torch.from_numpy(user_features)
     data['business'].x = torch.from_numpy(biz_features)
     data['user'].y = torch.from_numpy(user_labels)
     data['business'].y = torch.from_numpy(biz_labels)
     data['user','user_user','user'].edge_index = torch.from_numpy(user_user_arr)
     data['user','owns','business'].edge_index = torch.from_numpy(user_biz_arr)
     # etc.
     ```
2. **DGL**  
   - Similarly, import edges and features into a **heterograph** with node types “user” and “business.”

3. **Homogeneous Graph**  
   - If you prefer a single graph, offset business IDs by `num_users` and unify feature/label arrays, or keep a `node_type` feature. However, a hetero-graph is recommended for clarity.

---

## **When to Rerun This Notebook**

- **New Scenario**: If you generate fresh data in `low_fraud` instead of `high_fraud`, rerun the notebook to create scenario-specific .npy files.  
- **Adjusted Feature Engineering**: If you add new suspicious signals or transformations, you’ll need to regenerate the feature matrices.  
- **Model Refresh**: Whenever user or business columns or relationships change significantly.