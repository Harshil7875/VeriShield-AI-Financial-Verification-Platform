{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Notebook: 02-Model-Training-GNN-PyTorch-4.ipynb (Extended for IP & Multi-Task)\n",
    "# =============================================================================\n",
    "# This notebook demonstrates multi-task GNN training on processed GNN data\n",
    "# that includes user, business, and IP nodes, plus masks for train/val/test.\n",
    "# Now using synergy-based IP labels from your new data pipeline,\n",
    "# and a correct steps_per_epoch formula for mini-batching (if desired).\n",
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GNN data at: /Users/harshil/Developer/GitHub_Repos/VeriShield-AI-Financial-Verification-Platform/verishield_ml_experiments/data_generators/data-v1/medium_fraud/processed_gnn\n",
      "MULTI_TASK=True, IP_CLASSIFICATION=True\n",
      "HIDDEN_DIM=64, LR=0.001, EPOCHS=10, BATCH_SIZE=1024\n",
      "Initial STEPS_PER_EPOCH=1 (may override after loading data)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Cell 2: Configuration\n",
    "# --------------------------------------------------------------------------------\n",
    "# Path to synergy-based data (already preprocessed into .npy files)\n",
    "PROCESSED_DIR = (\n",
    "    \"/Users/harshil/Developer/\"\n",
    "    \"GitHub_Repos/VeriShield-AI-Financial-Verification-Platform/\"\n",
    "    \"verishield_ml_experiments/data_generators/data-v1/medium_fraud/processed_gnn\"\n",
    ")\n",
    "\n",
    "# Multi-task toggles\n",
    "MULTI_TASK = True          # or False if only user classification\n",
    "IP_CLASSIFICATION = True   # classify IP nodes?\n",
    "\n",
    "# GNN Hyperparams\n",
    "HIDDEN_DIM = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 10\n",
    "\n",
    "# BATCH-SIZE & STEPS_PER_EPOCH:\n",
    "#  - If you do mini-batch training, steps_per_epoch = ceil(train_size / BATCH_SIZE).\n",
    "#  - If you do full-batch (the code currently does a single forward on the entire graph),\n",
    "#    then steps_per_epoch=1 is typical. \n",
    "BATCH_SIZE = 1024   # example batch size if you do mini-batching\n",
    "STEPS_PER_EPOCH = 1 # we'll override this later once we load train masks, if we want\n",
    "\n",
    "PRINT_EVERY = 1\n",
    "\n",
    "print(f\"Processed GNN data at: {PROCESSED_DIR}\")\n",
    "print(f\"MULTI_TASK={MULTI_TASK}, IP_CLASSIFICATION={IP_CLASSIFICATION}\")\n",
    "print(f\"HIDDEN_DIM={HIDDEN_DIM}, LR={LEARNING_RATE}, EPOCHS={EPOCHS}, BATCH_SIZE={BATCH_SIZE}\")\n",
    "print(f\"Initial STEPS_PER_EPOCH={STEPS_PER_EPOCH} (may override after loading data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded user_features.npy, shape=(10000, 7), dtype=float32\n",
      "Loaded user_labels.npy, shape=(10000,), dtype=int64\n",
      "Loaded biz_features.npy, shape=(2500, 3), dtype=float32\n",
      "Loaded biz_labels.npy, shape=(2500,), dtype=int64\n",
      "Loaded ip_features.npy, shape=(2500, 0), dtype=float32\n",
      "Loaded ip_labels.npy, shape=(2500,), dtype=int64\n",
      "Loaded edge_user_user.npy, shape=(2, 1024), dtype=int64\n",
      "Loaded edge_user_biz.npy, shape=(2, 21350), dtype=int64\n",
      "Loaded edge_user_ip.npy, shape=(2, 10000), dtype=int64\n",
      "Loaded train_mask_users.npy, shape=(10000,), dtype=bool\n",
      "Loaded val_mask_users.npy, shape=(10000,), dtype=bool\n",
      "Loaded test_mask_users.npy, shape=(10000,), dtype=bool\n",
      "Loaded train_mask_biz.npy, shape=(2500,), dtype=bool\n",
      "Loaded val_mask_biz.npy, shape=(2500,), dtype=bool\n",
      "Loaded test_mask_biz.npy, shape=(2500,), dtype=bool\n",
      "Loaded train_mask_ip.npy, shape=(2500,), dtype=bool\n",
      "Loaded val_mask_ip.npy, shape=(2500,), dtype=bool\n",
      "Loaded test_mask_ip.npy, shape=(2500,), dtype=bool\n",
      "\n",
      "metadata.json contents:\n",
      "  scenario: medium_fraud\n",
      "  num_users: 10000\n",
      "  num_businesses: 2500\n",
      "  num_ips: 2500\n",
      "  user_feature_cols: ['segment_code', 'is_ring_leader', 'ip_count_log', 'phone_susp', 'email_susp', 'country_watch', 'burst_signup']\n",
      "  biz_feature_cols: ['watchlist_regctry', 'susp_name_flag', 'biz_age_log']\n",
      "  ip_feature_cols: []\n",
      "  do_split: True\n",
      "  train_ratio: 0.7\n",
      "  val_ratio: 0.15\n",
      "  test_ratio: 0.15\n",
      "  SINGLE_TASK_USER_ONLY: False\n",
      "  edges_user_user_count: 1024\n",
      "  edges_user_biz_count: 21350\n",
      "  edges_user_ip_count: 10000\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Cell 3: Loading .npy Arrays\n",
    "# --------------------------------------------------------------------------------\n",
    "def load_npy(filename):\n",
    "    path = os.path.join(PROCESSED_DIR, filename)\n",
    "    arr = np.load(path)\n",
    "    print(f\"Loaded {filename}, shape={arr.shape}, dtype={arr.dtype}\")\n",
    "    return arr\n",
    "\n",
    "user_features  = torch.from_numpy(load_npy(\"user_features.npy\")).float()\n",
    "user_labels    = torch.from_numpy(load_npy(\"user_labels.npy\")).long()\n",
    "biz_features   = torch.from_numpy(load_npy(\"biz_features.npy\")).float()\n",
    "biz_labels     = torch.from_numpy(load_npy(\"biz_labels.npy\")).long()\n",
    "ip_features    = torch.from_numpy(load_npy(\"ip_features.npy\")).float()\n",
    "ip_labels      = torch.from_numpy(load_npy(\"ip_labels.npy\")).long()\n",
    "\n",
    "edge_user_user = torch.from_numpy(load_npy(\"edge_user_user.npy\")).long()\n",
    "edge_user_biz  = torch.from_numpy(load_npy(\"edge_user_biz.npy\")).long()\n",
    "edge_user_ip   = torch.from_numpy(load_npy(\"edge_user_ip.npy\")).long()\n",
    "\n",
    "# Load train/val/test masks\n",
    "train_mask_users = None\n",
    "val_mask_users   = None\n",
    "test_mask_users  = None\n",
    "try:\n",
    "    train_mask_users = torch.from_numpy(load_npy(\"train_mask_users.npy\")).bool()\n",
    "    val_mask_users   = torch.from_numpy(load_npy(\"val_mask_users.npy\")).bool()\n",
    "    test_mask_users  = torch.from_numpy(load_npy(\"test_mask_users.npy\")).bool()\n",
    "except FileNotFoundError:\n",
    "    print(\"No user masks found; will do full-batch on users if MULTI_TASK=False.\")\n",
    "\n",
    "train_mask_biz = None\n",
    "val_mask_biz   = None\n",
    "test_mask_biz  = None\n",
    "if MULTI_TASK:\n",
    "    try:\n",
    "        train_mask_biz = torch.from_numpy(load_npy(\"train_mask_biz.npy\")).bool()\n",
    "        val_mask_biz   = torch.from_numpy(load_npy(\"val_mask_biz.npy\")).bool()\n",
    "        test_mask_biz  = torch.from_numpy(load_npy(\"test_mask_biz.npy\")).bool()\n",
    "    except FileNotFoundError:\n",
    "        print(\"No business masks found; can't do multi-task effectively without them.\")\n",
    "\n",
    "train_mask_ip = None\n",
    "val_mask_ip   = None\n",
    "test_mask_ip  = None\n",
    "if IP_CLASSIFICATION:\n",
    "    try:\n",
    "        train_mask_ip = torch.from_numpy(load_npy(\"train_mask_ip.npy\")).bool()\n",
    "        val_mask_ip   = torch.from_numpy(load_npy(\"val_mask_ip.npy\")).bool()\n",
    "        test_mask_ip  = torch.from_numpy(load_npy(\"test_mask_ip.npy\")).bool()\n",
    "    except FileNotFoundError:\n",
    "        print(\"No IP masks found; IP classification won't be possible without them.\")\n",
    "\n",
    "# Optionally load metadata.json\n",
    "meta_path = os.path.join(PROCESSED_DIR, \"metadata.json\")\n",
    "if os.path.isfile(meta_path):\n",
    "    with open(meta_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    print(\"\\nmetadata.json contents:\")\n",
    "    for k,v in metadata.items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted STEPS_PER_EPOCH = 7 (from user train count=7000, batch_size=1024)\n",
      "Final STEPS_PER_EPOCH: 7\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Cell 4: Adjust STEPS_PER_EPOCH if Doing Mini-Batch\n",
    "# --------------------------------------------------------------------------------\n",
    "# The code below still does \"full-batch\" training, but here's how you'd compute steps_per_epoch \n",
    "# if you truly do mini-batching at the node level (not shown in detail here).\n",
    "# We'll pick 'user' training set size to define steps_per_epoch, for instance:\n",
    "\n",
    "if train_mask_users is not None:\n",
    "    train_user_count = train_mask_users.sum().item()\n",
    "    if train_user_count > 0:\n",
    "        STEPS_PER_EPOCH = math.ceil(train_user_count / BATCH_SIZE)\n",
    "        print(f\"Adjusted STEPS_PER_EPOCH = {STEPS_PER_EPOCH} (from user train count={train_user_count}, batch_size={BATCH_SIZE})\")\n",
    "    else:\n",
    "        # fallback to 1 if no users in train set\n",
    "        STEPS_PER_EPOCH = 1\n",
    "else:\n",
    "    # full-batch\n",
    "    STEPS_PER_EPOCH = 1\n",
    "\n",
    "print(f\"Final STEPS_PER_EPOCH: {STEPS_PER_EPOCH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HeteroData object created with node_types: ['user', 'business', 'ip']\n",
      "Edge types: [('user', 'user_user', 'user'), ('user', 'user_business', 'business'), ('user', 'user_ip', 'ip'), ('business', 'rev_user_business', 'user'), ('ip', 'rev_user_ip', 'user')]\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Cell 5: Build a HeteroData Graph (Users, Businesses, IPs)\n",
    "# --------------------------------------------------------------------------------\n",
    "data = HeteroData()\n",
    "\n",
    "# user nodes\n",
    "data['user'].x = user_features\n",
    "data['user'].y = user_labels\n",
    "if train_mask_users is not None:\n",
    "    data['user'].train_mask = train_mask_users\n",
    "    data['user'].val_mask   = val_mask_users\n",
    "    data['user'].test_mask  = test_mask_users\n",
    "\n",
    "# business nodes\n",
    "data['business'].x = biz_features\n",
    "data['business'].y = biz_labels\n",
    "if MULTI_TASK and train_mask_biz is not None:\n",
    "    data['business'].train_mask = train_mask_biz\n",
    "    data['business'].val_mask   = val_mask_biz\n",
    "    data['business'].test_mask  = test_mask_biz\n",
    "\n",
    "# ip nodes\n",
    "data['ip'].x = ip_features\n",
    "data['ip'].y = ip_labels\n",
    "if IP_CLASSIFICATION and train_mask_ip is not None:\n",
    "    data['ip'].train_mask  = train_mask_ip\n",
    "    data['ip'].val_mask    = val_mask_ip\n",
    "    data['ip'].test_mask   = test_mask_ip\n",
    "\n",
    "# Edges\n",
    "data[('user','user_user','user')].edge_index = edge_user_user\n",
    "data[('user','user_business','business')].edge_index = edge_user_biz\n",
    "data[('user','user_ip','ip')].edge_index = edge_user_ip\n",
    "\n",
    "# Reverse edges for message passing in both directions\n",
    "rev_user_biz = torch.flip(edge_user_biz, dims=[0])\n",
    "data[('business','rev_user_business','user')].edge_index = rev_user_biz\n",
    "\n",
    "rev_user_ip = torch.flip(edge_user_ip, dims=[0])\n",
    "data[('ip','rev_user_ip','user')].edge_index = rev_user_ip\n",
    "\n",
    "print(\"\\nHeteroData object created with node_types:\", list(data.node_types))\n",
    "print(\"Edge types:\", list(data.edge_types))\n",
    "\n",
    "# Move entire data to GPU\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FraudGNN(\n",
      "  (conv1): HeteroConv(num_relations=5)\n",
      "  (conv2): HeteroConv(num_relations=5)\n",
      "  (user_lin): Linear(64, 2, bias=True)\n",
      "  (business_lin): Linear(64, 2, bias=True)\n",
      "  (ip_lin): Linear(64, 2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Cell 6: Define a GNN Model (Supports Multi-Edges & Optional Multi-Task)\n",
    "# --------------------------------------------------------------------------------\n",
    "class FraudGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim=64, user_out=2, biz_out=2, ip_out=2,\n",
    "                 multi_task=False, ip_task=False):\n",
    "        \"\"\"\n",
    "        multi_task=True => We'll produce heads for user + business\n",
    "        ip_task=True    => We'll also produce a head for IP\n",
    "\n",
    "        Otherwise, we do a single user head only.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.multi_task = multi_task\n",
    "        self.ip_task = ip_task\n",
    "\n",
    "        # Single HeteroConv for all relevant edges:\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('user','user_user','user'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('user','user_business','business'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('business','rev_user_business','user'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('user','user_ip','ip'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('ip','rev_user_ip','user'): SAGEConv((-1, -1), hidden_dim),\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('user','user_user','user'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('user','user_business','business'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('business','rev_user_business','user'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('user','user_ip','ip'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('ip','rev_user_ip','user'): SAGEConv((-1, -1), hidden_dim),\n",
    "        }, aggr='mean')\n",
    "\n",
    "        # Final linear heads\n",
    "        self.user_lin = Linear(hidden_dim, user_out)\n",
    "\n",
    "        if multi_task:\n",
    "            self.business_lin = Linear(hidden_dim, biz_out)\n",
    "        else:\n",
    "            self.business_lin = None\n",
    "\n",
    "        if ip_task:\n",
    "            self.ip_lin = Linear(hidden_dim, ip_out)\n",
    "        else:\n",
    "            self.ip_lin = None\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # 1st layer\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        for ntype, x in x_dict.items():\n",
    "            x_dict[ntype] = F.relu(x)\n",
    "\n",
    "        # 2nd layer\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        for ntype, x in x_dict.items():\n",
    "            x_dict[ntype] = F.relu(x)\n",
    "\n",
    "        return x_dict\n",
    "\n",
    "    def forward_user(self, emb_dict):\n",
    "        return self.user_lin(emb_dict['user'])\n",
    "\n",
    "    def forward_business(self, emb_dict):\n",
    "        if self.business_lin is None:\n",
    "            return None\n",
    "        return self.business_lin(emb_dict['business'])\n",
    "\n",
    "    def forward_ip(self, emb_dict):\n",
    "        if self.ip_lin is None:\n",
    "            return None\n",
    "        return self.ip_lin(emb_dict['ip'])\n",
    "\n",
    "model = FraudGNN(\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    user_out=2,         # user classification: legit/fraud\n",
    "    biz_out=2,          # business classification\n",
    "    ip_out=2,           # IP classification\n",
    "    multi_task=MULTI_TASK,\n",
    "    ip_task=IP_CLASSIFICATION\n",
    ").to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Cell 7: Training Setup (Multi-Task or Single)\n",
    "# --------------------------------------------------------------------------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def train_step():\n",
    "    \"\"\"\n",
    "    One train step on the entire graph (masked to train sets).\n",
    "    If truly doing mini-batch, you'd sample subgraph or node-batches here\n",
    "    instead of passing the entire data each step.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    emb_dict = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    # User classification\n",
    "    user_logits = model.forward_user(emb_dict)\n",
    "    train_mask_u = data['user'].train_mask if 'train_mask' in data['user'] else None\n",
    "    user_loss = 0.\n",
    "    if train_mask_u is not None:\n",
    "        masked_logits = user_logits[train_mask_u]\n",
    "        masked_labels = data['user'].y[train_mask_u]\n",
    "        user_loss = F.cross_entropy(masked_logits, masked_labels)\n",
    "    else:\n",
    "        user_loss = F.cross_entropy(user_logits, data['user'].y)\n",
    "\n",
    "    # Business classification (multi-task)\n",
    "    biz_loss = 0.\n",
    "    if model.multi_task and 'train_mask' in data['business']:\n",
    "        biz_logits = model.forward_business(emb_dict)\n",
    "        train_mask_b = data['business'].train_mask\n",
    "        masked_biz_logits = biz_logits[train_mask_b]\n",
    "        masked_biz_labels = data['business'].y[train_mask_b]\n",
    "        biz_loss = F.cross_entropy(masked_biz_logits, masked_biz_labels)\n",
    "\n",
    "    # IP classification (ip_task)\n",
    "    ip_loss = 0.\n",
    "    if model.ip_task and 'train_mask' in data['ip']:\n",
    "        ip_logits = model.forward_ip(emb_dict)\n",
    "        train_mask_i = data['ip'].train_mask\n",
    "        masked_ip_logits = ip_logits[train_mask_i]\n",
    "        masked_ip_labels = data['ip'].y[train_mask_i]\n",
    "        ip_loss = F.cross_entropy(masked_ip_logits, masked_ip_labels)\n",
    "\n",
    "    total_loss = user_loss + biz_loss + ip_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(total_loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_user(mask_name='val_mask'):\n",
    "    \"\"\"Compute user accuracy on val/test mask.\"\"\"\n",
    "    model.eval()\n",
    "    emb_dict = model(data.x_dict, data.edge_index_dict)\n",
    "    user_logits = model.forward_user(emb_dict)\n",
    "    if mask_name not in data['user']:\n",
    "        preds = user_logits.argmax(dim=-1)\n",
    "        correct = (preds == data['user'].y).sum()\n",
    "        return float(correct / len(data['user'].y))\n",
    "    mask = data['user'][mask_name]\n",
    "    logits_masked = user_logits[mask]\n",
    "    labels_masked = data['user'].y[mask]\n",
    "    preds = logits_masked.argmax(dim=-1)\n",
    "    correct = (preds == labels_masked).sum()\n",
    "    return float(correct / mask.sum())\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_biz(mask_name='val_mask'):\n",
    "    \"\"\"Compute business accuracy if multi-task is enabled.\"\"\"\n",
    "    if not model.multi_task or mask_name not in data['business']:\n",
    "        return 0.0\n",
    "    model.eval()\n",
    "    emb_dict = model(data.x_dict, data.edge_index_dict)\n",
    "    biz_logits = model.forward_business(emb_dict)\n",
    "    mask = data['business'][mask_name]\n",
    "    logits_masked = biz_logits[mask]\n",
    "    labels_masked = data['business'].y[mask]\n",
    "    preds = logits_masked.argmax(dim=-1)\n",
    "    correct = (preds == labels_masked).sum()\n",
    "    return float(correct / mask.sum())\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_ip(mask_name='val_mask'):\n",
    "    \"\"\"Compute IP accuracy if IP classification is enabled.\"\"\"\n",
    "    if not model.ip_task or mask_name not in data['ip']:\n",
    "        return 0.0\n",
    "    model.eval()\n",
    "    emb_dict = model(data.x_dict, data.edge_index_dict)\n",
    "    ip_logits = model.forward_ip(emb_dict)\n",
    "    mask = data['ip'][mask_name]\n",
    "    logits_masked = ip_logits[mask]\n",
    "    labels_masked = data['ip'].y[mask]\n",
    "    preds = logits_masked.argmax(dim=-1)\n",
    "    correct = (preds == labels_masked).sum()\n",
    "    return float(correct / mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 => loss=2.1874, user_val_acc=0.5753, biz_val_acc=0.7787, ip_val_acc=0.5973\n",
      "Epoch 2/10 => loss=1.9114, user_val_acc=0.5867, biz_val_acc=0.7787, ip_val_acc=0.6213\n",
      "Epoch 3/10 => loss=1.9275, user_val_acc=0.5840, biz_val_acc=0.7787, ip_val_acc=0.6320\n",
      "Epoch 4/10 => loss=1.8964, user_val_acc=0.5860, biz_val_acc=0.7787, ip_val_acc=0.6347\n",
      "Epoch 5/10 => loss=1.8842, user_val_acc=0.6053, biz_val_acc=0.7787, ip_val_acc=0.6160\n",
      "Epoch 6/10 => loss=1.8789, user_val_acc=0.6080, biz_val_acc=0.7787, ip_val_acc=0.6133\n",
      "Epoch 7/10 => loss=1.8727, user_val_acc=0.6127, biz_val_acc=0.7787, ip_val_acc=0.6213\n",
      "Epoch 8/10 => loss=1.8675, user_val_acc=0.6147, biz_val_acc=0.7787, ip_val_acc=0.6213\n",
      "Epoch 9/10 => loss=1.8623, user_val_acc=0.6147, biz_val_acc=0.7787, ip_val_acc=0.6133\n",
      "Epoch 10/10 => loss=1.8572, user_val_acc=0.6147, biz_val_acc=0.7787, ip_val_acc=0.6107\n",
      "\n",
      "Final Evaluations:\n",
      "User Test Accuracy: 0.6420\n",
      "Business Test Accuracy: 0.7653\n",
      "IP Test Accuracy: 0.6053\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Cell 8: Main Training Loop\n",
    "# --------------------------------------------------------------------------------\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    avg_loss = 0.0\n",
    "    for step in range(STEPS_PER_EPOCH):\n",
    "        # If truly mini-batching, you'd do subgraph sampling here.\n",
    "        loss_val = train_step()\n",
    "        avg_loss += loss_val\n",
    "\n",
    "    if STEPS_PER_EPOCH > 1:\n",
    "        avg_loss /= STEPS_PER_EPOCH\n",
    "\n",
    "    # Evaluate on validation masks\n",
    "    val_acc_user = evaluate_user('val_mask')\n",
    "    val_acc_biz  = evaluate_biz('val_mask') if MULTI_TASK else 0.0\n",
    "    val_acc_ip   = evaluate_ip('val_mask') if IP_CLASSIFICATION else 0.0\n",
    "\n",
    "    if epoch % PRINT_EVERY == 0:\n",
    "        print(f\"Epoch {epoch}/{EPOCHS} => loss={avg_loss:.4f}, \"\n",
    "              f\"user_val_acc={val_acc_user:.4f}, biz_val_acc={val_acc_biz:.4f}, ip_val_acc={val_acc_ip:.4f}\")\n",
    "\n",
    "# Final test evaluation\n",
    "print(\"\\nFinal Evaluations:\")\n",
    "user_test_acc = evaluate_user('test_mask')\n",
    "print(f\"User Test Accuracy: {user_test_acc:.4f}\")\n",
    "if MULTI_TASK:\n",
    "    biz_test_acc = evaluate_biz('test_mask')\n",
    "    print(f\"Business Test Accuracy: {biz_test_acc:.4f}\")\n",
    "if IP_CLASSIFICATION:\n",
    "    ip_test_acc = evaluate_ip('test_mask')\n",
    "    print(f\"IP Test Accuracy: {ip_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n",
      "We've built a multi-edge, multi-task GNN using PyTorch Geometric:\n",
      "- Node types: user, business, ip\n",
      "- Edge types: user->user, user->business, user->ip (+ reversed edges)\n",
      "- Multi-task heads for user, business, and IP classification\n",
      "- 'steps_per_epoch' formula demonstrated for mini-batch. \n",
      "- Final accuracy results printed for each node type.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Cell 9: Wrap-Up\n",
    "# --------------------------------------------------------------------------------\n",
    "print(\"\"\"\n",
    "Done!\n",
    "We've built a multi-edge, multi-task GNN using PyTorch Geometric:\n",
    "- Node types: user, business, ip\n",
    "- Edge types: user->user, user->business, user->ip (+ reversed edges)\n",
    "- Multi-task heads for user, business, and IP classification\n",
    "- 'steps_per_epoch' formula demonstrated for mini-batch. \n",
    "- Final accuracy results printed for each node type.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
