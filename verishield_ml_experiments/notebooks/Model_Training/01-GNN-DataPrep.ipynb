{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook: 01-GNN-DataPrep. Preparing synthetic data for GNN modeling.\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook: 01-GNN-DataPrep.ipynb\n",
    "# =========================================\n",
    "# This notebook prepares VeriShield synthetic data for GNN usage.\n",
    "# By: (Harshil Bhandari / 01-18-2025)\n",
    "\n",
    "# =====================================================================\n",
    "# Cell 1: Imports & Global Settings\n",
    "# =====================================================================\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For saving PyTorch structures, if desired (optional).\n",
    "import torch\n",
    "\n",
    "# If you want to create a PyG 'HeteroData' object, import relevant PyG classes.\n",
    "# import torch_geometric\n",
    "# from torch_geometric.data import HeteroData\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "print(\"Notebook: 01-GNN-DataPrep. Preparing synthetic data for GNN modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario path: /Users/harshil/Development/personal_projects/VeriShield-ML-Experiments/data_generators/data/high_fraud\n",
      "Processed output will go to: /Users/harshil/Development/personal_projects/VeriShield-ML-Experiments/data_generators/data/high_fraud/processed_gnn\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Cell 2: Configuration\n",
    "# =====================================================================\n",
    "SCENARIO = \"high_fraud\"  # \"low_fraud\", \"default\", etc.\n",
    "DATA_BASE_PATH = \"/Users/harshil/Development/personal_projects/VeriShield-ML-Experiments/data_generators/data\"\n",
    "OUTPUT_SUBFOLDER = \"processed_gnn\"\n",
    "\n",
    "# If you want to do a user node classification, set True. If multi-task, handle business as well.\n",
    "SINGLE_TASK_USER_ONLY = True\n",
    "\n",
    "# If you want to split nodes for train/val/test at the user level:\n",
    "DO_SPLIT = True\n",
    "\n",
    "# Example: 70/15/15 split\n",
    "TRAIN_RATIO = 0.70\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "# Paths\n",
    "scenario_path = os.path.join(DATA_BASE_PATH, SCENARIO)\n",
    "processed_dir = os.path.join(scenario_path, OUTPUT_SUBFOLDER)\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Scenario path: {scenario_path}\")\n",
    "print(f\"Processed output will go to: {processed_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames loaded successfully.\n",
      "\n",
      "Shapes:\n",
      "  Users: (100000, 18)\n",
      "  Businesses: (10000, 6)\n",
      "  User-Biz: (220942, 2)\n",
      "  User-User: (5029, 2)\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Cell 3: Load CSVs\n",
    "# =====================================================================\n",
    "try:\n",
    "    df_users = pd.read_csv(os.path.join(scenario_path, \"synthetic_users.csv\"))\n",
    "    df_businesses = pd.read_csv(os.path.join(scenario_path, \"synthetic_businesses.csv\"))\n",
    "    df_user_biz = pd.read_csv(os.path.join(scenario_path, \"user_business_relationships.csv\"))\n",
    "    df_user_user = pd.read_csv(os.path.join(scenario_path, \"user_user_relationships.csv\"))\n",
    "    print(\"DataFrames loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not load one of the main CSVs. {e}\")\n",
    "    sys.exit(\"Check your scenario folder or file paths.\")\n",
    "\n",
    "print(f\"\\nShapes:\")\n",
    "print(f\"  Users: {df_users.shape}\")\n",
    "print(f\"  Businesses: {df_businesses.shape}\")\n",
    "print(f\"  User-Biz: {df_user_biz.shape}\")\n",
    "print(f\"  User-User: {df_user_user.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic ID validation done.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Cell 4: Basic Validation & Checks\n",
    "# =====================================================================\n",
    "\n",
    "# 4.1 Check ID ranges\n",
    "max_user_id = df_users[\"user_id\"].max()\n",
    "expected_users = len(df_users)\n",
    "if max_user_id != expected_users:\n",
    "    print(f\"Warning: The max user_id is {max_user_id}, but we have {expected_users} rows. Possibly okay if data generator used a different approach.\")\n",
    "\n",
    "# Similarly for businesses\n",
    "max_biz_id = df_businesses[\"business_id\"].max()\n",
    "expected_biz = len(df_businesses)\n",
    "if max_biz_id != expected_biz:\n",
    "    print(f\"Warning: The max business_id is {max_biz_id}, but we have {expected_biz} rows. Possibly okay if data generator used a different approach.\")\n",
    "\n",
    "# 4.2 Check user_user edges\n",
    "bad_uids_uu = df_user_user[ (df_user_user['from_user_id'] < 1) | (df_user_user['from_user_id'] > expected_users) |\n",
    "                            (df_user_user['to_user_id'] < 1)   | (df_user_user['to_user_id'] > expected_users) ]\n",
    "if len(bad_uids_uu) > 0:\n",
    "    print(f\"Found {len(bad_uids_uu)} out-of-range user_user edges. Dropping them.\")\n",
    "    df_user_user = df_user_user.drop(bad_uids_uu.index)\n",
    "\n",
    "# 4.3 Check user_biz edges\n",
    "bad_uids_ub = df_user_biz[ (df_user_biz['user_id'] < 1) | (df_user_biz['user_id'] > expected_users) ]\n",
    "bad_bids_ub = df_user_biz[ (df_user_biz['business_id'] < 1) | (df_user_biz['business_id'] > expected_biz) ]\n",
    "if len(bad_uids_ub) > 0:\n",
    "    print(f\"Found {len(bad_uids_ub)} out-of-range user IDs in user_biz. Dropping them.\")\n",
    "    df_user_biz = df_user_biz.drop(bad_uids_ub.index)\n",
    "if len(bad_bids_ub) > 0:\n",
    "    print(f\"Found {len(bad_bids_ub)} out-of-range business IDs in user_biz. Dropping them.\")\n",
    "    df_user_biz = df_user_biz.drop(bad_bids_ub.index)\n",
    "\n",
    "print(\"\\nBasic ID validation done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature engineering done. Example user columns now include: ['user_id', 'segment', 'name', 'email', 'username', 'birthdate', 'gender', 'signup_ip', 'device_id', 'phone', 'country_code', 'created_at', 'burst_signup', 'fraud_label', 'is_ring_leader', 'email_domain', 'ip_count', 'num_fraud_biz_owned', 'segment_code', 'ip_count_log', 'country_watch', 'phone_susp', 'email_susp']\n",
      "Example business columns now include: ['business_id', 'business_name', 'registration_country', 'incorporation_date', 'owner_name', 'fraud_label', 'watchlist_regctry', 'susp_name_flag', 'biz_age_days', 'biz_age_log']\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Cell 5: Feature Engineering\n",
    "# =====================================================================\n",
    "# We'll define some helper functions to transform certain columns.\n",
    "\n",
    "def encode_segment(seg):\n",
    "    \"\"\"Return an integer code for each segment string.\"\"\"\n",
    "    mapping = {\"casual\": 0, \"smb_owner\": 1, \"enterprise\": 2, \"money_mule\": 3}\n",
    "    return mapping.get(seg, 0)\n",
    "\n",
    "def watchlist_country(ctry):\n",
    "    \"\"\"Return 1 if ctry is in watchlist, else 0.\"\"\"\n",
    "    watchlist = [\"NK\", \"IR\", \"SY\", \"CU\", \"AF\", \"SO\", \"LY\"]\n",
    "    if ctry in watchlist:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def suspicious_name(bname):\n",
    "    \"\"\"Check if the business_name has suspicious keywords.\"\"\"\n",
    "    suspicious_keywords = [\"test\", \"fake\", \"shell\", \"phantom\", \"bogus\", \"shady\"]\n",
    "    bname_lower = str(bname).lower()\n",
    "    return 1 if any(kw in bname_lower for kw in suspicious_keywords) else 0\n",
    "\n",
    "# We can create numeric feature arrays for users & businesses.\n",
    "\n",
    "# 5.1 Users\n",
    "df_users['segment_code'] = df_users['segment'].apply(encode_segment)\n",
    "df_users['burst_signup'] = df_users['burst_signup'].astype(int)  # boolean->0/1\n",
    "df_users['is_ring_leader'] = df_users.get('is_ring_leader', False).astype(int)  # boolean->0/1 if missing\n",
    "df_users['ip_count_log'] = np.log1p(df_users['ip_count'])  # optional log transform\n",
    "df_users['country_watch'] = df_users['country_code'].apply(watchlist_country)\n",
    "\n",
    "# Example: suspicious phone/email signals\n",
    "def phone_suspicious(phone):\n",
    "    phone = str(phone)\n",
    "    if len(phone) < 7:\n",
    "        return 1\n",
    "    if '+999' in phone or '666-666' in phone:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def email_suspicious(email):\n",
    "    email = str(email).lower()\n",
    "    return 1 if any(dom in email for dom in [\"@tempmail.xyz\",\"@fakemail.com\",\"@guerrillamail.com\"]) else 0\n",
    "\n",
    "df_users['phone_susp'] = df_users['phone'].apply(phone_suspicious)\n",
    "df_users['email_susp'] = df_users['email'].apply(email_suspicious)\n",
    "\n",
    "# Fill missing numeric columns with 0\n",
    "num_cols_users = ['ip_count','ip_count_log','phone_susp','email_susp','country_watch']\n",
    "for c in num_cols_users:\n",
    "    df_users[c] = df_users[c].fillna(0)\n",
    "\n",
    "# 5.2 Businesses\n",
    "df_businesses['watchlist_regctry'] = df_businesses['registration_country'].apply(watchlist_country)\n",
    "df_businesses['susp_name_flag'] = df_businesses['business_name'].apply(suspicious_name)\n",
    "\n",
    "# For biz 'incorporation_date' we can do an 'age_in_days' from a reference:\n",
    "def days_since_incorp(date):\n",
    "    if pd.isnull(date):\n",
    "        return 0\n",
    "    # or a reference date, say \"today\"\n",
    "    ref_date = pd.Timestamp.now()\n",
    "    delta = ref_date - pd.to_datetime(date)\n",
    "    return delta.days\n",
    "\n",
    "df_businesses['biz_age_days'] = df_businesses['incorporation_date'].apply(days_since_incorp)\n",
    "df_businesses['biz_age_log'] = np.log1p(df_businesses['biz_age_days'])\n",
    "\n",
    "# Fill missing numeric\n",
    "num_cols_biz = ['watchlist_regctry','susp_name_flag','biz_age_days','biz_age_log']\n",
    "for c in num_cols_biz:\n",
    "    df_businesses[c] = df_businesses[c].fillna(0)\n",
    "\n",
    "print(\"\\nFeature engineering done. Example user columns now include:\", df_users.columns.tolist())\n",
    "print(\"Example business columns now include:\", df_businesses.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Constructed 10058 user-user edges (including possible duplicates for undirected).\n",
      "Constructed 220942 user-business edges.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Cell 6: Node ID Assignment & Edge Building\n",
    "# =====================================================================\n",
    "num_users = len(df_users)\n",
    "num_biz = len(df_businesses)\n",
    "\n",
    "# We'll do 0-based indexing for users, 0-based for businesses, but offset for business if we do a single graph\n",
    "# If using a heterograph approach, keep them separate.\n",
    "\n",
    "# 6.1 Create user_idx and biz_idx columns\n",
    "# user_id in [1..num_users], so subtract 1 to get [0..num_users-1]\n",
    "df_users['node_id'] = df_users['user_id'] - 1\n",
    "df_businesses['node_id'] = df_businesses['business_id'] - 1\n",
    "\n",
    "# 6.2 Build user-user edges\n",
    "# For ring leaders\n",
    "df_user_user['from_id_0'] = df_user_user['from_user_id'] - 1\n",
    "df_user_user['to_id_0'] = df_user_user['to_user_id'] - 1\n",
    "\n",
    "# If we want them undirected, we might create a second set of edges reversed. We'll show a simple approach:\n",
    "edges_user_user = []\n",
    "for idx, row in df_user_user.iterrows():\n",
    "    f_id = row['from_id_0']\n",
    "    t_id = row['to_id_0']\n",
    "    edges_user_user.append((f_id, t_id))\n",
    "    # Possibly add reversed if you want undirected:\n",
    "    edges_user_user.append((t_id, f_id))\n",
    "\n",
    "# 6.3 Build user-business edges\n",
    "df_user_biz['user_id_0'] = df_user_biz['user_id'] - 1\n",
    "df_user_biz['biz_id_0'] = df_user_biz['business_id'] - 1\n",
    "\n",
    "edges_user_biz = []\n",
    "for idx, row in df_user_biz.iterrows():\n",
    "    # user is row['user_id_0'], business is row['biz_id_0']\n",
    "    edges_user_biz.append((row['user_id_0'], row['biz_id_0']))\n",
    "\n",
    "print(f\"\\nConstructed {len(edges_user_user)} user-user edges (including possible duplicates for undirected).\")\n",
    "print(f\"Constructed {len(edges_user_biz)} user-business edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature shape: (100000, 7), Business feature shape: (10000, 3)\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Cell 7: Creating Feature Arrays & Labels\n",
    "# =====================================================================\n",
    "# 7.1 user_features\n",
    "# We'll pick a subset of columns to represent user features numerically:\n",
    "# segment_code, is_ring_leader, ip_count_log, phone_susp, email_susp, country_watch, burst_signup, etc.\n",
    "user_feature_cols = [\n",
    "    'segment_code','is_ring_leader','ip_count_log','phone_susp',\n",
    "    'email_susp','country_watch','burst_signup'\n",
    "]\n",
    "# Convert to numpy in node_id order\n",
    "df_users_sorted = df_users.sort_values('node_id')\n",
    "user_features = df_users_sorted[user_feature_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "# user_label (fraud_label)\n",
    "user_labels = df_users_sorted['fraud_label'].astype(int).to_numpy()\n",
    "\n",
    "# 7.2 business_features\n",
    "biz_feature_cols = [\n",
    "    'watchlist_regctry','susp_name_flag','biz_age_log'\n",
    "]\n",
    "df_biz_sorted = df_businesses.sort_values('node_id')\n",
    "biz_features = df_biz_sorted[biz_feature_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "# business fraud label\n",
    "biz_labels = df_biz_sorted['fraud_label'].astype(int).to_numpy()\n",
    "\n",
    "print(f\"User feature shape: {user_features.shape}, Business feature shape: {biz_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User node splits: train=70000, val=15000, test=15000\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Cell 8: Optional Train/Val/Test Split for user nodes\n",
    "# =====================================================================\n",
    "train_mask_users = None\n",
    "val_mask_users = None\n",
    "test_mask_users = None\n",
    "\n",
    "if DO_SPLIT:\n",
    "    # We'll do a random split of user node IDs\n",
    "    user_node_ids = df_users_sorted['node_id'].to_numpy()\n",
    "    # Shuffle\n",
    "    np.random.shuffle(user_node_ids)\n",
    "    n_train = int(TRAIN_RATIO * num_users)\n",
    "    n_val = int(VAL_RATIO * num_users)\n",
    "    # n_test = remaining\n",
    "\n",
    "    train_ids = user_node_ids[:n_train]\n",
    "    val_ids = user_node_ids[n_train:n_train+n_val]\n",
    "    test_ids = user_node_ids[n_train+n_val:]\n",
    "\n",
    "    # We'll create boolean masks for shape [num_users]\n",
    "    train_mask_users = np.zeros(num_users, dtype=bool)\n",
    "    val_mask_users = np.zeros(num_users, dtype=bool)\n",
    "    test_mask_users = np.zeros(num_users, dtype=bool)\n",
    "\n",
    "    train_mask_users[train_ids] = True\n",
    "    val_mask_users[val_ids] = True\n",
    "    test_mask_users[test_ids] = True\n",
    "\n",
    "    print(f\"\\nUser node splits: train={train_mask_users.sum()}, val={val_mask_users.sum()}, test={test_mask_users.sum()}\")\n",
    "\n",
    "# If multi-task with business labels, we could do something similar for businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All processed data saved to: /Users/harshil/Development/personal_projects/VeriShield-ML-Experiments/data_generators/data/high_fraud/processed_gnn\n",
      "Data prep complete!\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Cell 9: Saving Processed Data\n",
    "# =====================================================================\n",
    "# We'll store arrays in the processed_gnn folder. \n",
    "# You can store them as .npy, .pt, or .pkl, or build a HeteroData object if you prefer PyG.\n",
    "\n",
    "# Let's do .npy for example:\n",
    "np.save(os.path.join(processed_dir, \"user_features.npy\"), user_features)\n",
    "np.save(os.path.join(processed_dir, \"user_labels.npy\"), user_labels)\n",
    "np.save(os.path.join(processed_dir, \"biz_features.npy\"), biz_features)\n",
    "np.save(os.path.join(processed_dir, \"biz_labels.npy\"), biz_labels)\n",
    "\n",
    "# Edge lists\n",
    "# We'll store them as arrays of shape [2, num_edges] for potential usage in PyTorch Geometric.\n",
    "user_user_arr = np.array(edges_user_user, dtype=np.int64).T  # shape (2, E_uu)\n",
    "user_biz_arr = np.array(edges_user_biz, dtype=np.int64).T    # shape (2, E_ub)\n",
    "\n",
    "np.save(os.path.join(processed_dir, \"edge_user_user.npy\"), user_user_arr)\n",
    "np.save(os.path.join(processed_dir, \"edge_user_biz.npy\"), user_biz_arr)\n",
    "\n",
    "# Masks\n",
    "if DO_SPLIT:\n",
    "    np.save(os.path.join(processed_dir, \"train_mask_users.npy\"), train_mask_users)\n",
    "    np.save(os.path.join(processed_dir, \"val_mask_users.npy\"), val_mask_users)\n",
    "    np.save(os.path.join(processed_dir, \"test_mask_users.npy\"), test_mask_users)\n",
    "\n",
    "# Optionally store a small metadata .json \n",
    "metadata = {\n",
    "    \"scenario\": SCENARIO,\n",
    "    \"num_users\": num_users,\n",
    "    \"num_businesses\": num_biz,\n",
    "    \"user_feature_cols\": user_feature_cols,\n",
    "    \"biz_feature_cols\": biz_feature_cols,\n",
    "    \"do_split\": DO_SPLIT,\n",
    "    \"train_ratio\": TRAIN_RATIO,\n",
    "    \"val_ratio\": VAL_RATIO,\n",
    "    \"test_ratio\": TEST_RATIO,\n",
    "    \"SINGLE_TASK_USER_ONLY\": SINGLE_TASK_USER_ONLY,\n",
    "    \"edges_user_user_count\": user_user_arr.shape[1],\n",
    "    \"edges_user_biz_count\": user_biz_arr.shape[1],\n",
    "}\n",
    "with open(os.path.join(processed_dir, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\nAll processed data saved to:\", processed_dir)\n",
    "print(\"Data prep complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
